# 一、摘要

大型語言模型 (Large Language Models) 在各領域被廣泛應用且不斷發展，逐漸成為日常生活工作生活的一部份。然而，LLM 仍有幻覺問題 (Hallucination) 卻會造成反覆錯誤資訊的生成結果，造成使用者對 LLM 產生迷信，進而影響 LLM 在搜尋與檢索 (Information Retrieval) 應用上的信任感。本研究探討如何降低 LLM 產生錯誤結果，使其更準確地幫助使用者解決問題。我們以文本資料庫為基礎，使用者的需求描述與文本資料庫中之文本進行向量化比較，並進一步針對錯誤進行總結與解釋。本研究旨在透過改良的檢索式生成 (Retrieval Augmented Generation)，使大型語言模型的回應內容更為可靠，提高使用者對其信任度。

# 二、研究動機與研究問題

## (一)、研究動機

目前 ChatGPT 評估及大模型在模型 (Large Language Models) 以下簡稱 LLM 透過結構化或是非結構化的表現，卻容易被特別訓練的 LLM 甚至在客製化試驗時的表現，卻容易受到驗證的資料呈現方式的影響。

然而，在這些令人驚艷的表現背後，有些問題逐漸浮出檯面，其中幻覺問題 (Hallucination) 是一大隱憂。當 LLM 在生成回覆時，由於缺乏及時的校對與事實確認的階段，因此有可能會忽略客觀證據、邏輯推理、常識判斷。實則予誤導、錯誤信息的回答，會使用者無法辨別真假，可能導致嚴重後果。為了改善此問題，檢索增強生成 (Retrieval Augmented Generation) 以下簡稱 RAG 模式開始受到關注。RAG 模式的本質是，藉由提供 LLM 相關的上下文資訊，來降低其產生幻覺的可能性。然而，傳統 RAG 模式仍存在一些問題，例如：檢索效率、斷線、信息的過濾、過濾掉重要資訊等。因此，本研究旨在透過改良 RAG 模式，來提升 LLM 的準確性與可靠性，並降低其產生幻覺問題的機率，進而提升使用者對 LLM 的信任感。

## (二)、研究問題

本研究主要探討如何透過改良檢索增強生成 (Retrieval Augmented Generation) 模式，降低大型語言模型 (Large Language Models) 產生幻覺問題的機率，並提升使用者對其信任感。具體而言，本研究將探討以下問題：

1. 如何提升檢索式生成 (RAG) 模式中檢索的效率與準確性？
2. 如何有效過濾掉檢索到的無關資訊，並保留重要的上下文資訊？
3. 如何設計有效的提示詞 (Prompt) ，引導 LLM 產生更準確、更可靠的回覆？
4. 改良後的檢索式生成 (RAG) 模式是否能有效降低 LLM 產生幻覺問題的機率？
5. 使用者對改良後的檢索式生成 (RAG) 模式所產生的回覆，是否具有更高的信任感？

## 五、結果與討論

以下是使用 all-MiniLM-L6-v2 作為 Embedding model，在不同問題下，更改不同 Top-K 尋找的實驗結果。

| Covid-19 Wiki Q1   |   Top-K |   Precision |   AP |   NDCG |
|--------------------|---------|-------------|------|--------|
|                    |       5 |        1    | 1    |   1    |
|                    |      10 |        0.9  | 0.96 |   0.93 |
|                    |      20 |        0.65 | 0.93 |   0.75 |

| Covid-19 Wiki Q2   |   Top-K |   Precision |   AP |   NDCG |
|--------------------|---------|-------------|------|--------|
|                    |       5 |        0.6  | 0.92 |   0.7  |
|                    |      10 |        0.3  | 0.92 |   0.45 |
|                    |      20 |        0.15 | 0.92 |   0.3  |

| Covid-19 Wiki Q3   |   Top-K |   Precision |   AP |   NDCG |
|--------------------|---------|-------------|------|--------|
|                    |       5 |         0.8 | 1    |   0.87 |
|                    |      10 |         0.5 | 0.91 |   0.63 |
|                    |      20 |         0.3 | 0.81 |   0.44 |

**Q1:** What measures take people to prevent COVID-19 while they are outside? **Q2:** What is the name of the virus that causes COVID-19? **Q3:** How can I tell if I have COVID-19?

以下是使用 all-MiniLM-L6-v2 作為 Embedding model，在不同問題下，加上自 CG 拓展比較後所取得的實驗結果。

| Linux Update Q1   |   Top-K |   Precision |   AP |   NDCG |
|-------------------|---------|-------------|------|--------|
|                   |       5 |         1   | 1    |   1    |
|                   |      10 |         1   | 1    |   1    |
|                   |      20 |         0.8 | 0.92 |   0.85 |

| Linux Update Q2   |   Top-K |   Precision |   AP |   NDCG |
|-------------------|---------|-------------|------|--------|
|                   |       5 |         1   | 1    |   1    |
|                   |      10 |         0.8 | 0.92 |   0.89 |
|                   |      20 |         0.6 | 0.88 |   0.63 |

| Linux Update Q3   |   Top-K |   Precision |   AP |   NDCG |
|-------------------|---------|-------------|------|--------|
|                   |       5 |         1   | 1    |   1    |
|                   |      10 |         0.8 | 0.91 |   0.87 |
|                   |      20 |         0.6 | 0.85 |   0.6  |

| Linux Update Q4   |   Top-K |   Precision |   AP |   NDCG |
|-------------------|---------|-------------|------|--------|
|                   |       5 |         1   | 1    |   1    |
|                   |      10 |         0.8 | 0.92 |   0.89 |
|                   |      20 |         0.6 | 0.88 |   0.63 |