import os
import glob
import pandas as pd
import uuid
import time
import requests
from qdrant_client import QdrantClient, models

# --- 1. åŸºæœ¬è¨­å®š (è«‹ç¢ºä¿è·¯å¾‘æ­£ç¢º) ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
os.chdir(BASE_DIR)

EMBED_API_URL = "https://ws-04.wade0426.me/embed"
LLM_API_URL = "https://ws-05.huannago.com/v1/chat/completions" # ä½¿ç”¨æ‚¨ä¹‹å‰çš„ URL
LLM_MODEL = "google/gemma-3-27b-it" # ä½¿ç”¨ Gemma-3
API_KEY = "YOUR_API_KEY" # âš ï¸ è«‹å¡«å…¥æ‚¨çš„ API Key

client = QdrantClient(url="http://localhost:6333")
COLLECTION_NAME = "gemma_multi_turn_rag"

# --- 2. å·¥å…·å‡½æ•¸ ---

def get_embedding(texts: list):
    """å–å¾—å‘é‡"""
    try:
        res = requests.post(EMBED_API_URL, json={
            "texts": texts, "normalize": True, "task_description": "æª¢ç´¢æŠ€è¡“æ–‡ä»¶"
        }, timeout=60)
        return res.json()["embeddings"]
    except Exception as e:
        print(f"âŒ Embedding éŒ¯èª¤: {e}")
        return None

def call_llm(prompt: str):
    """å‘¼å« LLM (Gemma-3)"""
    try:
        payload = {
            "model": LLM_MODEL,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0
        }
        headers = {"Authorization": f"Bearer {API_KEY}"}
        res = requests.post(LLM_API_URL, json=payload, headers=headers, timeout=120)
        return res.json()['choices'][0]['message']['content'].strip()
    except Exception as e:
        return f"LLM å‘¼å«å‡ºéŒ¯: {e}"

# --- 3. çŸ¥è­˜åº«åˆå§‹åŒ– (Step 1/2) ---

def initialize_db():
    print(f"ğŸ“¡ æ­£åœ¨åˆå§‹åŒ– Qdrant: {COLLECTION_NAME}...")
    
    # åµæ¸¬æª”æ¡ˆ (æ”¯æ´æœ‰ç„¡ (1) çš„æƒ…æ³)
    file_paths = sorted(glob.glob("data_0*(1).txt") or glob.glob("data_0*.txt"))
    
    if not file_paths:
        print("âš ï¸ æ‰¾ä¸åˆ° data_0*.txtï¼Œè·³éåˆå§‹åŒ–ã€‚")
        return

    # å–å¾—å‘é‡ç¶­åº¦
    sample_vec = get_embedding(["test"])[0]
    dim = len(sample_vec)

    if client.collection_exists(COLLECTION_NAME):
        client.delete_collection(COLLECTION_NAME)
    
    client.create_collection(
        collection_name=COLLECTION_NAME,
        vectors_config=models.VectorParams(size=dim, distance=models.Distance.COSINE)
    )

    all_points = []
    for path in file_paths:
        file_name = os.path.basename(path)
        print(f"ğŸ“– è®€å–æª”æ¡ˆ: {file_name}")
        with open(path, 'r', encoding='utf-8') as f:
            content = f.read()
            # ç°¡å–®åˆ‡åˆ† (æ¯ 400 å­—ä¸€æ®µ)
            chunks = [content[i:i+400] for i in range(0, len(content), 350)]
            vectors = get_embedding(chunks)
            for chunk, vec in zip(chunks, vectors):
                all_points.append(models.PointStruct(
                    id=str(uuid.uuid4()), vector=vec,
                    payload={"text": chunk, "source": file_name}
                ))
    
    client.upsert(collection_name=COLLECTION_NAME, points=all_points)
    print(f"âœ… çŸ¥è­˜åº«åŒ¯å…¥å®Œæˆï¼Œå…± {len(all_points)} ç­†ã€‚")

# --- 4. åŸ·è¡Œä»»å‹™ (Step 2/2) ---

def run_task():
    input_file = "Re_Write_questions.csv"
    if not os.path.exists(input_file):
        print(f"âŒ æ‰¾ä¸åˆ° {input_file}")
        return

    df = pd.read_csv(input_file)
    df['answer'] = ""
    df['source'] = ""
    
    # æ ¸å¿ƒï¼šå°è©±è¨˜æ†¶å­—å…¸
    session_history = {} 

    print("\nğŸš€ é–‹å§‹è™•ç†å¤šè¼ª RAG ä»»å‹™...")

    for i, row in df.iterrows():
        cid = str(row['conversation_id'])
        q = str(row['questions'])
        
        # å–å¾—è©²å°è©±çš„æ­·å²
        history = session_history.get(cid, "å°šæœªé–‹å§‹å°è©±")

        print(f"\nğŸ‘‰ [Q{i+1}] CID:{cid} | {q}")

        # é—œéµæ­¥é©Ÿ 1ï¼šQuery Rewrite (æŸ¥è©¢é‡å¯«)
        rewrite_prompt = (
            f"ä½ æ˜¯ä¸€å€‹æœå°‹èªå¥å„ªåŒ–å°ˆå®¶ã€‚è«‹åƒè€ƒå°è©±æ­·å²ï¼Œå°‡ã€Œæœ€æ–°å•é¡Œã€æ”¹å¯«æˆä¸€å€‹èªæ„å®Œæ•´ã€é©åˆæœå°‹çš„ç¨ç«‹å¥å­ã€‚\n"
            f"ã€æ­·å²ã€‘ï¼š\n{history}\n"
            f"ã€æœ€æ–°å•é¡Œã€‘ï¼š{q}\n"
            f"è«‹ç›´æ¥è¼¸å‡ºæ”¹å¯«å¾Œçš„å¥å­ï¼š"
        )
        rewritten_q = call_llm(rewrite_prompt)
        print(f"   ğŸ” æ”¹å¯«å¾Œ: {rewritten_q}")

        # é—œéµæ­¥é©Ÿ 2ï¼šæª¢ç´¢ (ä½¿ç”¨æ”¹å¯«å¾Œçš„å•é¡Œ)
        q_vec = get_embedding([rewritten_q])[0]
        search_res = client.query_points(
            collection_name=COLLECTION_NAME, query=q_vec, limit=3
        ).points
        
        context = "\n".join([p.payload['text'] for p in search_res])
        source = search_res[0].payload['source'] if search_res else "æœªçŸ¥"

        # é—œéµæ­¥é©Ÿ 3ï¼šæ ¹æ“šæª¢ç´¢çµæœå›ç­”
        final_prompt = (
            f"è«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šå›ç­”å•é¡Œã€‚è‹¥è³‡è¨Šä¸è¶³è«‹èª å¯¦å›ç­”ç„¡æ³•å›ç­”ã€‚\n"
            f"ã€è³‡è¨Šã€‘ï¼š\n{context}\n"
            f"ã€å•é¡Œã€‘ï¼š{q}\n"
            f"å›ç­”ï¼š"
        )
        answer = call_llm(final_prompt)
        print(f"   ğŸ’¡ å›ç­”: {answer[:30]}...")

        # æ›´æ–°è©² CID çš„æ­·å²
        session_history[cid] = history + f"\nå•ï¼š{q}\nç­”ï¼š{answer}\n"
        
        # å¯«å…¥ DataFrame
        df.at[i, 'answer'] = answer
        df.at[i, 'source'] = source
        time.sleep(0.5)

    df.to_csv("Re_Write_questions_final.csv", index=False, encoding="utf-8-sig")
    print("\nğŸ‰ ä»»å‹™å®Œæˆï¼çµæœå„²å­˜è‡³: Re_Write_questions_final.csv")

if __name__ == "__main__":
    initialize_db()
    run_task()