import json
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# 1. åˆå§‹åŒ–æ¨¡å‹
llm = ChatOpenAI(
    base_url="https://ws-02.wade0426.me/v1",
    api_key="your_api_key_here", # è¨˜å¾—å¡«å…¥æ­£ç¢ºçš„ Key
    model="google/gemma-3-27b-it",
    temperature=0
)

# 2. å®šç¾©å·¥å…· (é‡é»ï¼šè¨»è§£å¿…é ˆå¯«å¾—éå¸¸æ˜ç¢º)
@tool
def generate_tech_summary(article_content: str):
    """
    é€™æ˜¯ä¸€å€‹ç§‘æŠ€æ–‡ç« æ‘˜è¦å·¥å…·ã€‚
    åªè¦ä½¿ç”¨è€…çš„è¼¸å…¥å…§å®¹åŒ…å«ï¼šAIã€äººå·¥æ™ºæ…§ã€è¼é”(NVIDIA)ã€å°ç©é›»ã€æ–°çš„æŠ€è¡“ç™¼ä½ˆã€æˆ–æ˜¯é•·ç¯‡çš„ç§‘æŠ€æ–°èï¼Œ
    è«‹ã€å‹™å¿…ã€å‘¼å«æ­¤å·¥å…·é€²è¡Œæ‘˜è¦ã€‚
    """
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€å€‹ç§‘æŠ€å°ˆå®¶ï¼Œè«‹å°‡ä»¥ä¸‹å…§å®¹æ¿ƒç¸®æˆä¸‰å€‹æ ¸å¿ƒé‡é»ã€‚"),
        ("user", "{text}")
    ])
    chain = prompt | llm | StrOutputParser()
    return chain.invoke({"text": article_content})

# 3. ç¶å®šå·¥å…·
llm_with_tools = llm.bind_tools([generate_tech_summary])

# 4. è·¯ç”±æç¤ºè© (é‡é»ï¼šçµ¦ AI æ˜ç¢ºçš„åˆ¤æ–·æº–å‰‡)
router_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€å€‹åˆ†é¡åŠ©æ‰‹ã€‚å¦‚æœä½¿ç”¨è€…çš„è¼¸å…¥çœ‹èµ·ä¾†åƒæ˜¯ä¸€ç¯‡ç§‘æŠ€æ–°èæˆ–æŠ€è¡“æè¿°ï¼Œè«‹å‘¼å« generate_tech_summaryã€‚å¦‚æœæ˜¯æ‰“æ‹›å‘¼(å¦‚ï¼šä½ å¥½)æˆ–æ—¥å¸¸å°è©±ï¼Œè«‹ç›´æ¥å›ç­”ã€‚"),
    ("user", "{user_input}")
])

# 5. äº’å‹•å¾ªç’°
while True:
    user_input = input("User: ")
    if user_input.lower() in ["exit", "q"]: break
    
    # æ³¨æ„é€™è£¡çš„ key å¿…é ˆæ˜¯ user_input
    ai_msg = (router_prompt | llm_with_tools).invoke({"user_input": user_input})
    
    if ai_msg.tool_calls:
        print(f"âœ… [æ±ºç­–] åµæ¸¬åˆ°ç§‘æŠ€å…§å®¹ï¼Œæ­£åœ¨è™•ç†...")
        tool_args = ai_msg.tool_calls[0]['args']
        final_result = generate_tech_summary.invoke(tool_args)
        print(f"ğŸ“„ [æ‘˜è¦çµæœ]:\n{final_result}")
    else:
        print(f"âŒ [æ±ºç­–] åˆ¤æ–·ç‚ºä¸€èˆ¬å°è©±")
        print(f"ğŸ’¬ [AI å›æ‡‰]: {ai_msg.content}")